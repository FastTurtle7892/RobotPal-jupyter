{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RobotPal] 서버 시작됨 | WebSocket: 9999, TCP: 9998\n",
      "[RobotPal] 통신 대기 중... (WS: 9999, TCP: 9998)\n",
      "[System] WebSocket 프로세서 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mChecking connectivity to the model hosters, this may take a while. To bypass this check, set `DISABLE_MODEL_SOURCE_CHECK` to `True`.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.big-log-text pre { font-size: 30px !important; line-height: 1.4 !important; font-weight: bold; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\user\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('korean_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\user\\.paddlex\\official_models\\korean_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Detector Ready!\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets\n",
    "import ipywidgets.widgets as widgets\n",
    "import traitlets\n",
    "from robotpal import Robot, Camera, bgr8_to_jpeg\n",
    "from robotpal.SCSCtrl import TTLServo\n",
    "from robotpal._core.server import SimulatorServer\n",
    "\n",
    "import threading\n",
    "import time\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "from vision.detector import PlateNumberDetector\n",
    "import threading\n",
    "import time\n",
    "\n",
    "display(HTML(\"<style>.big-log-text pre { font-size: 30px !important; line-height: 1.4 !important; font-weight: bold; }</style>\"))\n",
    "log_output = widgets.Output(layout={'border': '1px solid black', 'height': '300px', 'overflow_y': 'scroll'})\n",
    "log_output.add_class(\"big-log-text\")\n",
    "\n",
    "ocr_detector = PlateNumberDetector(\n",
    "    model=\"paddle\",\n",
    "    plate_similarity_thresh=80,\n",
    "    debug_mode=False  # 실전 모드 (카메라 영상 분석)\n",
    ")\n",
    "print(\"OCR Detector Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model load success\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e38830866ef4840af81e921bb310c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='areaA :'), Label(value='None'))), HBox(children=(Label(value='areaB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5158f3de454e44e6a25b0ff7a2474565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Image(value=b'', format='jpeg', height='224', width='224'), FloatSlider(value=0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df62194a16ad47939751794734d74304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='info', description='Start', style=ButtonStyle()), Label(value='Find Area :…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4158e9cd8e402296274350d42c1791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Label(value='Manual Controller'), Button(description='forward', layout=Layout(al…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa76ab0d8af44ca4bf7c6d35db25ae2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "robot = Robot()\n",
    "camera = Camera()\n",
    "# camera_ocr = Camera.instance(width=816, height=616)\n",
    "TTLServo.servoAngleCtrl(5, 45, 1, 100)\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "\n",
    "# .pth 파일의 경로를 확인\n",
    "model.load_state_dict(torch.load('best_steering_model_xy_test_12_17.pth'))\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model = model.eval().half()\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "print('model load success')\n",
    "\n",
    "lbl1 = ipywidgets.Label(value=\"areaA :\")\n",
    "areaAlbl = ipywidgets.Label(value=\"None\")\n",
    "hbox1 = widgets.HBox([lbl1, areaAlbl] )\n",
    "\n",
    "lbl2 = ipywidgets.Label(value=\"areaB :\")\n",
    "areaBlbl = ipywidgets.Label(value=\"None\")\n",
    "hbox2 = widgets.HBox([lbl2,areaBlbl])\n",
    "\n",
    "lbl3 = ipywidgets.Label(value=\"self.flag :\")\n",
    "flaglbl = ipywidgets.Label(value=\"None\")\n",
    "hbox3 = widgets.HBox([lbl3, flaglbl])\n",
    "vbox1 = widgets.VBox([hbox1, hbox2, hbox3])\n",
    "\n",
    "image_widget = ipywidgets.Image(format='jpeg', width=224, height=224)\n",
    "x_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "vbox2 = widgets.VBox([image_widget, x_slider, steering_slider], layout=widgets.Layout(align_self='center'))\n",
    "hbox4 = widgets.HBox([vbox2, y_slider, speed_slider], layout=widgets.Layout(align_self='center'))\n",
    "\n",
    "startBtn = widgets.Button(description=\"Start\", button_style='info')\n",
    "lbl41 = ipywidgets.Label(value=\"Find Area : \")\n",
    "goallbl = ipywidgets.Label(value=\"None\")\n",
    "hbox5 = widgets.HBox([startBtn,lbl41, goallbl])\n",
    "\n",
    "\n",
    "#수동 조작용 contorller widget 생성\n",
    "lbl50 = ipywidgets.Label(value=\"Manual Controller\")\n",
    "\n",
    "button_layout = widgets.Layout(width='100px', height='80px', align_self='center')\n",
    "stop_button = widgets.Button(description='stop', button_style='danger', layout=button_layout)\n",
    "forward_button = widgets.Button(description='forward', layout=button_layout)\n",
    "backward_button = widgets.Button(description='backward', layout=button_layout)\n",
    "left_button = widgets.Button(description='left', layout=button_layout)\n",
    "right_button = widgets.Button(description='right', layout=button_layout)\n",
    "middle_box = widgets.HBox([left_button, stop_button, right_button], layout=widgets.Layout(align_self='center'))\n",
    "controls_box = widgets.VBox([lbl50, forward_button, middle_box, backward_button])\n",
    "\n",
    "#자동 조작용 contorller widget 생성\n",
    "lbl51 = ipywidgets.Label(value=\"Auto Controller\")\n",
    "speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.25, description='speed gain',disabled = False)\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.2, description='steering gain',disabled = False)\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.5, description='steering kd',disabled = False)\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias',disabled = False)\n",
    "vbox3 = widgets.VBox([lbl51,speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider])\n",
    "hbox6 = widgets.HBox([controls_box, vbox3], layout=widgets.Layout(align_self='center'))\n",
    "log_output = ipywidgets.Output(layout={'border': '1px solid black', 'height': '800px', 'overflow_y': 'scroll'})\n",
    "\n",
    "display(vbox1, hbox4,hbox5,hbox6, log_output)\n",
    "\n",
    "def print_log(message):\n",
    "    log_output.append_stdout(message + \"\\n\")\n",
    "\n",
    "manual_btnlst = [stop_button, forward_button, backward_button, left_button, right_button]\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "def stop(change):\n",
    "    robot.stop()\n",
    "    \n",
    "def step_forward(change):\n",
    "    robot.forward(0.4)\n",
    "\n",
    "def step_backward(change):\n",
    "    robot.backward(0.4)\n",
    "\n",
    "def step_left(change):\n",
    "    robot.left(0.3)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()\n",
    "\n",
    "def step_right(change):\n",
    "    robot.right(0.3)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()\n",
    "\n",
    "stop_button.on_click(stop)\n",
    "forward_button.on_click(step_forward)\n",
    "backward_button.on_click(step_backward)\n",
    "left_button.on_click(step_left)\n",
    "right_button.on_click(step_right)\n",
    "\n",
    "# areaA 와 areaB 를 선정\n",
    "areaA = 'mint'\n",
    "areaB = 'darkblue'\n",
    "# 조사한 색상의 이름과 min, max HSV 값, 그리고 회전 각도(angle)를 담은 리스트\n",
    "# [수정] colors 리스트 (여러 타겟을 리스트 []로 묶음)\n",
    "colors = [\n",
    "    # targets: 해당 영역에서 찾아야 할 차량 번호들 (리스트 형태)\n",
    "    {'name': 'red',      'lower': np.array([3, 217, 214]),   'upper': np.array([4, 222, 218]),    'angle': 0,     'targets': [] },\n",
    "    {'name': 'mint',     'lower': np.array([68, 17, 221]),   'upper': np.array([70, 20, 222]),    'angle': 32.70, 'targets': ['263주0300', '255도7345'] }, \n",
    "    {'name': 'blue',     'lower': np.array([106, 212, 207]), 'upper': np.array([108, 223, 216]),  'angle': 29.47, 'targets': [] }, \n",
    "    {'name': 'darkblue', 'lower': np.array([120, 201, 182]), 'upper': np.array([120, 206, 189]),  'angle': 29.57, 'targets': ['187고1604', '249마1706'] }, \n",
    "    {'name': 'yellow',   'lower': np.array([27, 85, 195]),   'upper': np.array([30, 97, 221]),    'angle': 0,     'targets': [] },\n",
    "    {'name': 'orange',   'lower': np.array([17, 145, 222]),  'upper': np.array([18, 154, 224]),   'angle': 0,     'targets': [] }\n",
    "]\n",
    "\n",
    "areaA_color = next((color for color in colors if color['name'] == areaA), None)\n",
    "areaB_color = next((color for color in colors if color['name'] == areaB), None)\n",
    "\n",
    "areaAlbl.value = areaA_color['name']\n",
    "areaBlbl.value = areaB_color['name']\n",
    "\n",
    "findArea = areaA\n",
    "goallbl.value = findArea\n",
    "\n",
    "#frame 크기와 카메라 중심점 좌표 설정\n",
    "frame_width = 224\n",
    "frame_height = 224\n",
    "camera_center_X = int(frame_width/2)\n",
    "camera_center_Y = int(frame_height/2)\n",
    "\n",
    "#WorkingAreaFind() 용 리스트와 변수\n",
    "colorHSVvalueList = []\n",
    "max_len = 20\n",
    "\n",
    "#2개 thread 용 객체 변수 생성\n",
    "roadFinding = None\n",
    "goalFinding = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# 쓰레드 간 통신을 위한 이벤트 객체\n",
    "ocr_trigger_event = threading.Event()  # \"OCR 시작해!\" 신호\n",
    "ocr_done_event = threading.Event()     # \"OCR 다 했어!\" 신호\n",
    "\n",
    "# 데이터를 주고받을 공유 변수\n",
    "shared_ocr_image = None   # OCR 할 이미지 담을 곳\n",
    "shared_ocr_result = None  # 결과 담을 곳\n",
    "shared_target_list = []   # 찾아야 할 번호판 목록\n",
    "\n",
    "class OCRWorker(threading.Thread):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.daemon = True # 메인 프로그램 꺼지면 같이 꺼짐\n",
    "        self.running = True\n",
    "        \n",
    "    def run(self):\n",
    "        global shared_ocr_image, shared_ocr_result\n",
    "        \n",
    "        while self.running:\n",
    "            # 1. 일이 들어올 때까지 대기 (CPU 안 씀)\n",
    "            ocr_trigger_event.wait()\n",
    "            \n",
    "            # 이벤트가 꺼져있으면 다시 대기 (중복 방지)\n",
    "            if not ocr_trigger_event.is_set():\n",
    "                continue\n",
    "\n",
    "            print_log(\">>> OCR 연산 시작...\")\n",
    "            \n",
    "            # 2. OCR 수행\n",
    "            if shared_ocr_image is not None:\n",
    "                try:\n",
    "\n",
    "                    h, w, c = shared_ocr_image.shape\n",
    "                    print_log(f\">>> [Check] Input Image Size: {w}x{h}\")\n",
    "                    \n",
    "                    # 2. 이미지 파일로 저장 (현재 폴더에 저장됨)\n",
    "                    filename = f\"debug_ocr_input_{int(time.time())}.jpg\"\n",
    "                    cv2.imwrite(filename, shared_ocr_image)\n",
    "                    print_log(f\">>> [Saved] {filename} 저장됨! 확인해보세요.\")\n",
    "\n",
    "                    # 3. OCR 실행\n",
    "                    results = ocr_detector.detect(shared_ocr_image, target='255도7345')\n",
    "                    shared_ocr_result = results\n",
    "                except Exception as e:\n",
    "                    print_log(f\"OCR Error: {e}\")\n",
    "                    shared_ocr_result = None\n",
    "            else:\n",
    "                print_log(\"OCR Image is None\")\n",
    "                shared_ocr_result = None\n",
    "\n",
    "            # print_log(\"<<< [Thread 3] OCR 연산 완료!\")\n",
    "\n",
    "            # 3. 완료 신호 보내기\n",
    "            ocr_done_event.set()      # \"다 했어\" 깃발 들기\n",
    "            ocr_trigger_event.clear() # \"시작해\" 깃발 내리기\n",
    "\n",
    "\n",
    "class WorkingAreaFind(threading.Thread):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.th_flag = True\n",
    "        self.imageInput = 0\n",
    "        self.flag = 1\n",
    "        flaglbl.value = str(self.flag)\n",
    "        \n",
    "        # [중요] OCR 상태 변수 초기화\n",
    "        self.ocr_running = False \n",
    "        self.ocr_results = [] \n",
    "\n",
    "    def wait_and_show(self, seconds, message=\"\"):\n",
    "        if message:\n",
    "            print_log(f\"▶ {message}\")\n",
    "            \n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < seconds:\n",
    "            self.imageInput = camera.value\n",
    "            if message:\n",
    "                cv2.putText(self.imageInput, message, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            image_widget.value = bgr8_to_jpeg(self.imageInput)\n",
    "            time.sleep(0.05)\n",
    "\n",
    "    def run(self):\n",
    "        while self.th_flag:\n",
    "            self.imageInput = camera.value\n",
    "            hsv = cv2.cvtColor(self.imageInput, cv2.COLOR_BGR2HSV)\n",
    "            hsv = cv2.blur(hsv, (15, 15))\n",
    "                        \n",
    "            areaA_mask = cv2.inRange(hsv, areaA_color['lower'], areaA_color['upper'])\n",
    "            areaA_mask = cv2.erode(areaA_mask, None, iterations=2)\n",
    "            areaA_mask = cv2.dilate(areaA_mask, None, iterations=2)\n",
    "            \n",
    "            areaB_mask = cv2.inRange(hsv, areaB_color['lower'], areaB_color['upper'])\n",
    "            areaB_mask = cv2.erode(areaB_mask, None, iterations=2)\n",
    "            areaB_mask = cv2.dilate(areaB_mask, None, iterations=2)\n",
    "\n",
    "            AContours, _ = cv2.findContours(areaA_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            BContours, _ = cv2.findContours(areaB_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            if AContours and self.flag == 1:\n",
    "                self.findCenter(areaA, AContours)\n",
    "            elif BContours and self.flag == 2:\n",
    "                self.findCenter(areaB, BContours)\n",
    "            else:\n",
    "                cv2.putText(self.imageInput, \"Finding...\", (0, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "                image_widget.value = bgr8_to_jpeg(self.imageInput)\n",
    "            time.sleep(0.1)\n",
    "    \n",
    "    def findCenter(self, name, Contours):  \n",
    "        global roadFinding, findArea, shared_ocr_image, shared_ocr_result\n",
    "\n",
    "        c = max(Contours, key=cv2.contourArea)\n",
    "        ((box_x, box_y), radius) = cv2.minEnclosingCircle(c)\n",
    "\n",
    "        X = int(box_x)\n",
    "        Y = int(box_y)\n",
    "        \n",
    "        error_Y = abs(camera_center_Y - Y)\n",
    "        error_X = abs(camera_center_X - X)\n",
    "        \n",
    "        if error_Y < 15 and error_X < 15:\n",
    "            is_valid_target = False\n",
    "            if name == areaA and self.flag == 1:\n",
    "                is_valid_target = True\n",
    "            elif name == areaB and self.flag == 2:\n",
    "                is_valid_target = True\n",
    "            \n",
    "            if is_valid_target:\n",
    "                self.wait_and_show(1.0, \"Approaching Goal...\")\n",
    "\n",
    "                if 'roadFinding' in globals() and roadFinding:\n",
    "                    roadFinding.paused = True\n",
    "                robot.stop()\n",
    "\n",
    "                if name == areaA:\n",
    "                    self.flag = 2\n",
    "                    findArea = areaB\n",
    "                    goallbl.value = findArea\n",
    "                    areaAlbl.value = areaA + \" Goal!\"\n",
    "                    flaglbl.value = str(self.flag)\n",
    "                elif name == areaB:              \n",
    "                    self.flag = 1       \n",
    "                    findArea = areaB\n",
    "                    goallbl.value = findArea\n",
    "                    areaBlbl.value = areaB + \" Goal!\"\n",
    "                    flaglbl.value = str(self.flag)   \n",
    "\n",
    "                current_color_info = next((c for c in colors if c['name'] == name), None)\n",
    "                target_angle = current_color_info['angle'] if current_color_info else 0\n",
    "                target_list = current_color_info.get('targets', []) if current_color_info else []\n",
    "\n",
    "                if target_angle != 0:\n",
    "                    # 1. 준비 동작\n",
    "                    TTLServo.servoAngleCtrl(1, target_angle, 1, 100)\n",
    "                    self.wait_and_show(1.5, \"Adjusting Camera...\")\n",
    "\n",
    "                    # 2. 이미지 준비 (고화질)\n",
    "                    try: \n",
    "                        # 1. 서버 인스턴스 소환 (싱글톤이라 현재 실행 중인 서버가 잡힘)\n",
    "                        server = SimulatorServer.instance()\n",
    "                        \n",
    "                        # 2. 원본 데이터 가져오기\n",
    "                        raw_bytes = server.latest_jpeg\n",
    "                        \n",
    "                        if raw_bytes is not None:\n",
    "                            # 2. 바이트 -> 이미지 배열로 변환 (디코딩)\n",
    "                            nparr = np.frombuffer(raw_bytes, np.uint8)\n",
    "                            decoded_img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "                            \n",
    "                            # 3. 로봇 카메라는 뒤집혀 있는 경우가 많으므로 상하반전 (Flip)\n",
    "                            shared_ocr_image = cv2.flip(decoded_img, 0)\n",
    "                            \n",
    "                            h, w, _ = shared_ocr_image.shape\n",
    "                            print_log(f\"▶ 고화질 원본 추출 성공! ({w}x{h})\")\n",
    "                        else:\n",
    "                            # 데이터가 없으면 어쩔 수 없이 저화질 사용\n",
    "                            shared_ocr_image = camera.value.copy()\n",
    "                            print_log(\"▶ [경고] 원본 데이터(latest_jpeg) 없음 -> 저화질 사용\")\n",
    "                            \n",
    "                    except Exception as e: \n",
    "                        shared_ocr_image = None\n",
    "                        print_log(f\"▶ 이미지 디코딩 실패: {e}\")\n",
    "\n",
    "                    # 3. [핵심] Thread 3에게 일 시키기\n",
    "                    ocr_done_event.clear()    # 완료 깃발 내림\n",
    "                    ocr_trigger_event.set()   # \"시작해\" 깃발 올림\n",
    "\n",
    "                    # 4. 완료될 때까지 \"기다리면서 화면 갱신\" (이게 3-Thread의 장점)\n",
    "                    # OCR이 도는 동안 여기 while문이 계속 돌면서 화면을 그려줍니다.\n",
    "                    start_wait = time.time()\n",
    "                    while not ocr_done_event.is_set():\n",
    "                        self.imageInput = camera.value\n",
    "                        \n",
    "                        # 점 찍기 애니메이션 (Waiting...)\n",
    "                        elapsed = int(time.time() * 2) % 4\n",
    "                        dots = \".\" * elapsed\n",
    "                        cv2.putText(self.imageInput, f\"OCR Processing{dots}\", (10, 100), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "                        \n",
    "                        image_widget.value = bgr8_to_jpeg(self.imageInput)\n",
    "                        time.sleep(0.05)\n",
    "                        \n",
    "                        # 10초 넘으면 강제 탈출 (안전장치)\n",
    "                        if time.time() - start_wait > 30:\n",
    "                            print_log(\"OCR Timeout!\")\n",
    "                            break\n",
    "\n",
    "                    # 5. 결과 확인\n",
    "                    results = shared_ocr_result\n",
    "                    if results:\n",
    "                        detected_texts = []\n",
    "                        found_match = False\n",
    "                        \n",
    "                        # 리스트 안전 처리\n",
    "                        if not isinstance(results, list): results = [results]\n",
    "                        \n",
    "                        for res in results:\n",
    "                            if hasattr(res, 'text'):\n",
    "                                txt = res.text.replace(\" \", \"\").strip()\n",
    "                                detected_texts.append(txt)\n",
    "                                for t in target_list:\n",
    "                                    if t.replace(\" \", \"\").strip() == txt:\n",
    "                                        found_match = True\n",
    "                        \n",
    "                        print_log(f\"--- 결과: {detected_texts}\")\n",
    "                        msg = \"MATCH FOUND!\" if found_match else \"No Match\"\n",
    "                        self.wait_and_show(3.0, msg)\n",
    "                    else:\n",
    "                        self.wait_and_show(2.0, \"No Text Detected\")\n",
    "\n",
    "                    # 6. 복귀\n",
    "                    TTLServo.servoAngleCtrl(1, 0, 1, 100)\n",
    "                    self.wait_and_show(1.5, \"Returning...\")\n",
    "\n",
    "                else:\n",
    "                    self.wait_and_show(5.0, \"Frontal View...\")\n",
    "\n",
    "                if 'roadFinding' in globals() and roadFinding:\n",
    "                    roadFinding.paused = False\n",
    "                    \n",
    "        image_widget.value = bgr8_to_jpeg(self.imageInput)\n",
    "        \n",
    "    def stop(self):\n",
    "        self.th_flag = False\n",
    "        robot.stop()\n",
    "\n",
    "class RobotMoving(threading.Thread):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.th_flag = True\n",
    "        self.paused = False\n",
    "        self.angle = 0.0\n",
    "        self.angle_last = 0.0\n",
    "        \n",
    "    def run(self):\n",
    "        while self.th_flag:\n",
    "\n",
    "            if self.paused:\n",
    "                robot.stop()\n",
    "                time.sleep(0.1)\n",
    "                continue\n",
    "\n",
    "\n",
    "            image = camera.value\n",
    "            xy = model(self.preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "            x = xy[0]\n",
    "            y = (0.5 - xy[1]) / 2.0\n",
    "            \n",
    "            x_slider.value = x\n",
    "            y_slider.value = y\n",
    "            \n",
    "            #인공지능 무인운반로봇(AGV)의 속도 표시\n",
    "            speed_slider.value = 0.23\n",
    "            \n",
    "            image_widget.value = bgr8_to_jpeg(image)\n",
    "            \n",
    "            #조향값 계산\n",
    "            self.angle = np.arctan2(x, y)\n",
    "            \n",
    "            if not self.th_flag:\n",
    "                break\n",
    "            #PID 제어를 이용한 모터 제어\n",
    "            pid = self.angle * 0.2 + (self.angle - self.angle_last) * 0.5\n",
    "            self.angle_last = self.angle\n",
    "\n",
    "            #슬라이더에 표시\n",
    "            steering_slider.value = pid\n",
    "\n",
    "            robot.left_motor.value = max(min(speed_slider.value + steering_slider.value, 1.0), -0.9)\n",
    "            robot.right_motor.value =  max(min(speed_slider.value - steering_slider.value, 1.0), -0.9)\n",
    "            time.sleep(0.1)\n",
    "        robot.stop()\n",
    "    \n",
    "    def preprocess(self, image):\n",
    "        image = PIL.Image.fromarray(image)\n",
    "        image = transforms.functional.to_tensor(image).to(device).half()\n",
    "        image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "        return image[None, ...]\n",
    "\n",
    "    def stop(self):\n",
    "        self.th_flag = False\n",
    "        robot.stop()\n",
    "\n",
    "def start(change):\n",
    "    global camera_link, goalFinding, roadFinding, ocr_thread\n",
    "    \n",
    "    if startBtn.description == \"Start\" :\n",
    "        print_log(\"System Started! Target Finding Begin...\")\n",
    "        camera_link.unlink()\n",
    "        \n",
    "        # [핵심] OCR 쓰레드를 여기서 반드시 생성하고 시작해야 합니다!\n",
    "        ocr_thread = OCRWorker()\n",
    "        ocr_thread.start()\n",
    "        \n",
    "        goalFinding = WorkingAreaFind()\n",
    "        goalFinding.start()\n",
    "        \n",
    "        roadFinding = RobotMoving()\n",
    "        roadFinding.start()\n",
    "\n",
    "        startBtn.button_style = \"warning\" \n",
    "        startBtn.description = \"Stop\"\n",
    "    \n",
    "    elif startBtn.description == \"Stop\":\n",
    "        if roadFinding: roadFinding.stop()\n",
    "        if goalFinding: goalFinding.stop()\n",
    "        \n",
    "        # OCR 쓰레드 종료\n",
    "        if ocr_thread: \n",
    "            ocr_thread.running = False\n",
    "            # 대기 중인 쓰레드를 깨워서 종료시킴\n",
    "            ocr_trigger_event.set()\n",
    "        \n",
    "        camera_link = traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "            \n",
    "        startBtn.button_style = \"info\"\n",
    "        startBtn.description = \"Start\"\n",
    "\n",
    "startBtn.on_click(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(0.1)\n",
    "robot.stop()\n",
    "camera.stop()\n",
    "\n",
    "print('End')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
