{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RobotPal] ì„œë²„ ì‹œì‘ë¨ | WebSocket: 9999, TCP: 9998\n",
      "[RobotPal] í†µì‹  ëŒ€ê¸° ì¤‘... (WS: 9999, TCP: 9998)\n",
      "[System] WebSocket í”„ë¡œì„¸ì„œ ì‹œì‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCP] í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨ (('127.0.0.1', 49235))\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import PIL.Image\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "from ultralytics import YOLO  # YOLO ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€\n",
    "from robotpal import Robot, Camera, bgr8_to_jpeg\n",
    "from robotpal.SCSCtrl import TTLServo\n",
    "import os\n",
    "from datetime import datetime\n",
    "import ipywidgets.widgets as widgets\n",
    "import easyocr\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model.load_state_dict(torch.load('best_steering_model_xy_test_12_17.pth', map_location=torch.device('cuda')))\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model = model.eval().half()\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "model_yolo = YOLO(\"runs/detect/train/weights/best.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Send Servo] ID: 5, Angle: 24.988235294117647, Speed: 20.0\n",
      "[Send Servo] ID: 1, Angle: 0.0, Speed: 20.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b47dc0e08342fcb52106207dab788c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='500', width='500')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0823f5aeae435aab51795ef7ef51bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='[00:13:54] >>> OCR ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\\n[00:13:51] >>> OCR ëª¨ë¸ ë¡œë”© ì¤‘...\\n[00:13:51] >>> ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...\\n[00â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b26f5780464d88b1b0d62a88df2347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.0, description='y', max=1.0, orientation='vertical'), FloatSlider(value=0.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2584978cd74877879e59780a5938e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='x', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0faacaf13546929a2bcf4a5386a0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "opening handshake failed\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\websockets\\asyncio\\server.py\", line 356, in conn_handler\n",
      "    await connection.handshake(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\websockets\\asyncio\\server.py\", line 207, in handshake\n",
      "    raise self.protocol.handshake_exc\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\websockets\\server.py\", line 138, in accept\n",
      "    ) = self.process_request(request)\n",
      "        ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\websockets\\server.py\", line 233, in process_request\n",
      "    raise InvalidUpgrade(\n",
      "        \"Connection\", \", \".join(connection) if connection else None\n",
      "    )\n",
      "websockets.exceptions.InvalidUpgrade: missing Connection header\n",
      "Unhandled exception in client_connected_cb\n",
      "transport: <_SelectorSocketTransport closed fd=2284>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\jupyter ex\\robotpal\\_core\\server.py\", line 180, in _handle_tcp\n",
      "    await writer.wait_closed()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\streams.py\", line 358, in wait_closed\n",
      "    await self._protocol._get_close_waiter(self)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\selector_events.py\", line 1005, in _read_ready__data_received\n",
      "    data = self._sock.recv(self.max_size)\n",
      "ConnectionResetError: [WinError 10054] í˜„ì¬ ì—°ê²°ì€ ì›ê²© í˜¸ìŠ¤íŠ¸ì— ì˜í•´ ê°•ì œë¡œ ëŠê²¼ìŠµë‹ˆë‹¤\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCP] ì˜ˆì™¸ ë°œìƒ: [WinError 10054] í˜„ì¬ ì—°ê²°ì€ ì›ê²© í˜¸ìŠ¤íŠ¸ì— ì˜í•´ ê°•ì œë¡œ ëŠê²¼ìŠµë‹ˆë‹¤\n",
      "[TCP] ì—°ê²° ì¢…ë£Œ (('127.0.0.1', 49235))\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. ì´ˆê¸° ì„¤ì • ë° ë¡œê·¸ ì°½(Textarea) ìƒì„±\n",
    "# ==========================================\n",
    "CAM_WIDTH = 816\n",
    "CAM_HEIGHT = 616\n",
    "\n",
    "# [ìˆ˜ì •ë¨] Output ìœ„ì ¯ ëŒ€ì‹  Textarea ì‚¬ìš© (í™•ì‹¤í•œ ë¡œê·¸ ì¶œë ¥ìš©)\n",
    "log_widget = ipywidgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder=\"ë¡œê·¸ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤...\",\n",
    "    description=\"ğŸ“ LOG:\",\n",
    "    disabled=True, # ìˆ˜ì • ë¶ˆê°€ëŠ¥í•˜ê²Œ ì„¤ì •\n",
    "    layout=ipywidgets.Layout(width='600px', height='200px')\n",
    ")\n",
    "\n",
    "def log_print(msg):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ìƒìì— ë©”ì‹œì§€ë¥¼ ì§ì ‘ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "    new_line = f\"[{timestamp}] {msg}\\n\"\n",
    "    # ìƒˆë¡œìš´ ë¡œê·¸ë¥¼ ë§¨ ìœ„ì— ì¶”ê°€ (ìµœì‹ ìˆœ)\n",
    "    log_widget.value = new_line + log_widget.value \n",
    "\n",
    "\n",
    "robot = Robot()\n",
    "camera = Camera.instance(width=CAM_WIDTH, height=CAM_HEIGHT)\n",
    "TTLServo.servoAngleCtrl(5, -25, 1, 100)\n",
    "TTLServo.servoAngleCtrl(1, 0, 1, 100)\n",
    "\n",
    "# ==========================================\n",
    "# 2. ìœ„ì ¯ ìƒì„± ë° ë°°ì¹˜\n",
    "# ==========================================\n",
    "image_widget = ipywidgets.Image(format='jpeg', width=500, height=500)\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "display(image_widget)\n",
    "display(log_widget) # <--- [ìˆ˜ì •ë¨] í…ìŠ¤íŠ¸ ìƒì í‘œì‹œ\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. ê°ì§€ ìŠ¤ë ˆë“œ\n",
    "# ==========================================\n",
    "stop_thread = False\n",
    "detection_thread = None\n",
    "latest_image_lock = threading.Lock()\n",
    "shared_latest_image = None\n",
    "\n",
    "detection_result = {\n",
    "    \"box\": None,\n",
    "    \"dist_cm\": None,\n",
    "    \"detected\": False,\n",
    "    \"text\": \"\" \n",
    "}\n",
    "\n",
    "REF_DISTANCE_CM = 60.0\n",
    "REF_HEIGHT_PX = 110.0\n",
    "\n",
    "def detection_worker():\n",
    "    global shared_latest_image, stop_thread, detection_result\n",
    "\n",
    "    log_print(\">>> ê°ì§€ ìŠ¤ë ˆë“œ ì‹œì‘ë¨\")\n",
    "\n",
    "    while not stop_thread:\n",
    "        img_input = None\n",
    "        with latest_image_lock:\n",
    "            if shared_latest_image is not None:\n",
    "                img_input = shared_latest_image.copy()\n",
    "        \n",
    "        if img_input is None:\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # YOLO ì¶”ë¡ \n",
    "            results = model_yolo(img_input, verbose=False, conf=0.1) \n",
    "            \n",
    "            found = False\n",
    "            for result in results:\n",
    "                for box in result.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "                    \n",
    "                    h_pixel = y2 - y1\n",
    "                    dist = (REF_DISTANCE_CM * REF_HEIGHT_PX) / h_pixel if h_pixel > 0 else 0\n",
    "\n",
    "                    detection_result[\"box\"] = (x1, y1, x2, y2)\n",
    "                    detection_result[\"dist_cm\"] = dist\n",
    "                    detection_result[\"detected\"] = True\n",
    "                    found = True\n",
    "                    \n",
    "                    # 120cm ì´ë‚´ OCR ìˆ˜í–‰\n",
    "                    if dist < 120.0:\n",
    "                        try:\n",
    "                            h, w, _ = img_input.shape\n",
    "                            x1 = max(0, x1); y1 = max(0, y1)\n",
    "                            x2 = min(w, x2); y2 = min(h, y2)\n",
    "                            \n",
    "                            crop_img = img_input[y1:y2, x1:x2]\n",
    "                            \n",
    "                            if crop_img.shape[0] > 0 and crop_img.shape[1] > 0:\n",
    "                                ocr_texts = reader.readtext(crop_img, detail=0)\n",
    "                                if len(ocr_texts) > 0:\n",
    "                                    detection_result[\"text\"] = \" \".join(ocr_texts)\n",
    "                        except: pass\n",
    "                    break \n",
    "                if found: break\n",
    "\n",
    "            if not found:\n",
    "                detection_result[\"detected\"] = False\n",
    "                detection_result[\"box\"] = None\n",
    "        \n",
    "        except Exception as e:\n",
    "            log_print(f\"ğŸ”¥ ê°ì§€ ìŠ¤ë ˆë“œ ì—ëŸ¬: {e}\")\n",
    "            time.sleep(1.0)\n",
    "            \n",
    "        time.sleep(0.01)\n",
    "\n",
    "# ìŠ¤ë ˆë“œ ì¬ì‹œì‘\n",
    "stop_thread = True\n",
    "if detection_thread is not None:\n",
    "    detection_thread.join(timeout=1.0)\n",
    "\n",
    "stop_thread = False\n",
    "shared_latest_image = None\n",
    "detection_result = {\"box\": None, \"dist_cm\": None, \"detected\": False, \"text\": \"\"}\n",
    "\n",
    "detection_thread = threading.Thread(target=detection_worker)\n",
    "detection_thread.start()\n",
    "\n",
    "# ==========================================\n",
    "# 4. ë©”ì¸ ì‹¤í–‰ ë£¨í”„\n",
    "# ==========================================\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "stop_end_time = 0.0\n",
    "is_stopped = False\n",
    "frame_count = 0\n",
    "ignore_detection_until = 0.0 \n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last, is_stopped, stop_end_time, frame_count\n",
    "    global shared_latest_image, ignore_detection_until\n",
    "\n",
    "    try:\n",
    "        image = change['new']\n",
    "        current_time = time.time()\n",
    "        frame_count += 1\n",
    "\n",
    "        with latest_image_lock:\n",
    "            shared_latest_image = image\n",
    "\n",
    "        vis_image = image.copy()\n",
    "        \n",
    "        cur_box = detection_result[\"box\"]\n",
    "        cur_dist = detection_result[\"dist_cm\"]\n",
    "        is_detected = detection_result[\"detected\"]\n",
    "        cur_text = detection_result[\"text\"]\n",
    "\n",
    "        # --- [ìƒíƒœ 1] ì •ì§€ ëª¨ë“œ ---\n",
    "        if is_stopped:\n",
    "            if current_time < stop_end_time:\n",
    "                cv2.putText(vis_image, \"STOP MODE\", (10, 40), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)\n",
    "\n",
    "                remain_time = stop_end_time - current_time\n",
    "                cv2.putText(vis_image, f\"{remain_time:.1f}s\", (10, 80), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)\n",
    "                \n",
    "                if cur_box is not None:\n",
    "                    x1, y1, x2, y2 = cur_box\n",
    "                    cv2.rectangle(vis_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 3)\n",
    "                \n",
    "                robot.left_motor.value = 0.0\n",
    "                robot.right_motor.value = 0.0\n",
    "                image_widget.value = bgr8_to_jpeg(vis_image)\n",
    "                return\n",
    "            else:\n",
    "                is_stopped = False\n",
    "                ignore_detection_until = current_time + 3.0 \n",
    "                log_print(\">>> ì£¼í–‰ ì¬ê°œ (1.5ì´ˆê°„ ì¿¨ë‹¤ìš´)\")\n",
    "\n",
    "        # --- [ìƒíƒœ 2] ì£¼í–‰ ì¤‘ ê°ì§€ ---\n",
    "        if is_detected and cur_dist is not None:\n",
    "            x1, y1, x2, y2 = cur_box\n",
    "            color = (0, 255, 255) if current_time < ignore_detection_until else (0, 255, 0)\n",
    "            \n",
    "            cv2.rectangle(vis_image, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "\n",
    "            # ì •ì§€ ì¡°ê±´ (200cm ë¯¸ë§Œ)\n",
    "            if cur_dist < 150.0 and current_time > ignore_detection_until:\n",
    "                is_stopped = True\n",
    "                stop_end_time = current_time + 1.5\n",
    "                \n",
    "                # ì •ì§€í•  ë•Œ ë¡œê·¸ ì¶œë ¥\n",
    "                log_print(f\"ğŸ›‘ ì •ì§€! (ê±°ë¦¬: {cur_dist:.1f}cm) / ë²ˆí˜¸íŒ: [{cur_text}]\")\n",
    "                    \n",
    "                robot.left_motor.value = 0.0\n",
    "                robot.right_motor.value = 0.0\n",
    "                image_widget.value = bgr8_to_jpeg(vis_image)\n",
    "                return\n",
    "\n",
    "        image_widget.value = bgr8_to_jpeg(vis_image)\n",
    "\n",
    "        # --- [ìƒíƒœ 3] ììœ¨ ì£¼í–‰ ---\n",
    "        # ë¦¬ì‚¬ì´ì¦ˆ ì—†ì´ ì‹¤í–‰ (ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ ì¶œë ¥)\n",
    "        xy = model(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "        \n",
    "        x = xy[0]\n",
    "        y = (0.5 - xy[1]) / 2.0\n",
    "        \n",
    "        speed_slider.value = 0.32\n",
    "        \n",
    "        angle = np.arctan2(x, y)\n",
    "        pid = angle * 0.2 + (angle - angle_last) * 0.5\n",
    "        angle_last = angle\n",
    "        \n",
    "        steering_slider.value = pid + 0\n",
    "        left_val = max(min(speed_slider.value + steering_slider.value, 1.0), -0.9)\n",
    "        right_val = max(min(speed_slider.value - steering_slider.value, 1.0), -0.9)\n",
    "        \n",
    "        robot.left_motor.value = float(left_val)\n",
    "        robot.right_motor.value = float(right_val)\n",
    "        \n",
    "    except Exception as e:\n",
    "        robot.left_motor.value = 0.0\n",
    "        robot.right_motor.value = 0.0\n",
    "        log_print(f\"ğŸš¨ ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "        time.sleep(1.0)\n",
    "\n",
    "# ì‹¤í–‰ ì‹œì‘\n",
    "try: camera.unobserve_all()\n",
    "except: pass\n",
    "execute({'new': camera.value})\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í”„ë¡œì íŠ¸ ì¢…ë£Œí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "camera.unobserve(execute, names='value')\n",
    "time.sleep(0.1) \n",
    "robot.stop()\n",
    "camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
