# robot_vision.py
import threading
import time
import cv2
import torch
import torchvision
import torchvision.transforms as transforms
import PIL.Image
import easyocr
import numpy as np
from ultralytics import YOLO
from .robot_config import log_print, REF_DISTANCE_CM, REF_HEIGHT_PX

class VisionSystem:
    def __init__(self):
        self.device = torch.device('cuda')
        
        # --- ResNet (ì¡°í–¥) ëª¨ë¸ ë¡œë“œ ---
        log_print(">>> ì¡°í–¥ ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.steering_model = torchvision.models.resnet18(pretrained=False)
        self.steering_model.fc = torch.nn.Linear(512, 2)
        # ê²½ë¡œê°€ ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
        self.steering_model.load_state_dict(torch.load('best_steering_model_xy_test_12_17.pth', map_location=self.device))
        self.steering_model = self.steering_model.to(self.device).eval().half()
        
        self.mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()
        self.std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()

        # --- YOLO & OCR ëª¨ë¸ ë¡œë“œ ---
        log_print(">>> YOLO ë° OCR ëª¨ë¸ ë¡œë”© ì¤‘...")
        # í•™ìŠµí•œ ê³ í•´ìƒë„ OBB ëª¨ë¸ ê²½ë¡œ í™•ì¸ í•„ìš”
        self.model_yolo = YOLO("runs/obb/train/weights/best.pt")
        self.reader = easyocr.Reader(['en'], gpu=True)
        
        # --- ìŠ¤ë ˆë“œ ê³µìœ  ë³€ìˆ˜ ---
        self.stop_thread = False
        self.detection_thread = None
        self.latest_image_lock = threading.Lock()
        self.shared_latest_image = None
        
        self.detection_result = {
            "box": None,
            "dist_cm": None,
            "detected": False,
            "text": "" 
        }
        log_print(">>> ë¹„ì „ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def order_points(self, pts):
        """OBB 4ê°œ ì ì„ [ì¢Œìƒ, ìš°ìƒ, ìš°í•˜, ì¢Œí•˜] ìˆœì„œë¡œ ì •ë ¬í•˜ì—¬ ë°˜í™˜"""
        rect = np.zeros((4, 2), dtype="float32")
        
        # x+y í•©ì´ ê°€ì¥ ì‘ì€ ê²ƒì´ ì¢Œìƒë‹¨, ê°€ì¥ í° ê²ƒì´ ìš°í•˜ë‹¨
        s = pts.sum(axis=1)
        rect[0] = pts[np.argmin(s)]
        rect[2] = pts[np.argmax(s)]
        
        # y-x ì°¨ì´ê°€ ê°€ì¥ ì‘ì€ ê²ƒì´ ìš°ìƒë‹¨, ê°€ì¥ í° ê²ƒì´ ì¢Œí•˜ë‹¨
        diff = np.diff(pts, axis=1)
        rect[1] = pts[np.argmin(diff)]
        rect[3] = pts[np.argmax(diff)]
        
        return rect

    def preprocess(self, image):
        """ResNetìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        image = PIL.Image.fromarray(image)
        image = transforms.functional.to_tensor(image).to(self.device).half()
        image.sub_(self.mean[:, None, None]).div_(self.std[:, None, None])
        return image[None, ...]

    def update_image(self, image):
        """ë©”ì¸ ë£¨í”„ì—ì„œ ìµœì‹  ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì˜´"""
        with self.latest_image_lock:
            self.shared_latest_image = image

    def start_detection_thread(self):
        """ê°ì§€ ìŠ¤ë ˆë“œ ì‹œì‘"""
        if self.detection_thread is not None:
            self.stop_thread = True
            self.detection_thread.join()
        
        self.stop_thread = False
        self.detection_thread = threading.Thread(target=self._detection_worker)
        self.detection_thread.start()

    def stop_detection_thread(self):
        """ê°ì§€ ìŠ¤ë ˆë“œ ì¤‘ì§€"""
        self.stop_thread = True
        if self.detection_thread:
            self.detection_thread.join()

    def _detection_worker(self):
        log_print(">>> ê°ì§€ ìŠ¤ë ˆë“œ ì‹œì‘ë¨")
        while not self.stop_thread:
            img_input = None
            with self.latest_image_lock:
                if self.shared_latest_image is not None:
                    img_input = self.shared_latest_image.copy()
            
            if img_input is None:
                time.sleep(0.01)
                continue

            try:
                # YOLO ì¶”ë¡  (imgsz=800ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì •ë°€ë„ ìœ ì§€)
                results = self.model_yolo(img_input, verbose=False, conf=0.1, imgsz=800) 
                
                found = False
                for result in results:
                    if result.obb is None or len(result.obb) == 0:
                        continue

                    for obb in result.obb:
                        # 1. OBB 4ê°œ ê¼­ì§“ì  ì¢Œí‘œ ì¶”ì¶œ ë° ì •ë ¬
                        raw_points = obb.xyxyxyxy.cpu().numpy()[0].astype(np.float32)
                        ordered_points = self.order_points(raw_points)
                        
                        # 2. ê±°ë¦¬ ê³„ì‚°ì„ ìœ„í•œ ë†’ì´(H) ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                        x1, y1 = int(np.min(ordered_points[:, 0])), int(np.min(ordered_points[:, 1]))
                        x2, y2 = int(np.max(ordered_points[:, 0])), int(np.max(ordered_points[:, 1]))
                        
                        h_pixel = y2 - y1
                        dist = (REF_DISTANCE_CM * REF_HEIGHT_PX) / h_pixel if h_pixel > 0 else 0

                        self.detection_result["box"] = (x1, y1, x2, y2)
                        self.detection_result["dist_cm"] = dist
                        self.detection_result["detected"] = True
                        found = True
                        
                        # 3. ë¹„ìŠ¤ë“¬í•œ ë²ˆí˜¸íŒ ì •ë©´ìœ¼ë¡œ í´ê¸° (Warp Perspective)
                        if dist < 120.0:
                            try:
                                # ëª©ì ì§€ ì´ë¯¸ì§€ í¬ê¸° (ë²ˆí˜¸íŒ ë¹„ìœ¨ 4:1ì— ë§ì¶¤)
                                width, height = 400, 100
                                dst_pts = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype=np.float32)
                                
                                # ë³€í™˜ í–‰ë ¬ ê³„ì‚° ë° ì´ë¯¸ì§€ ì›Œí•‘
                                matrix = cv2.getPerspectiveTransform(ordered_points, dst_pts)
                                warped_img = cv2.warpPerspective(img_input, matrix, (width, height))
                                
                                # ê°€ë…ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ì „ì²˜ë¦¬ (ê·¸ë ˆì´ìŠ¤ì¼€ì¼)
                                warped_gray = cv2.cvtColor(warped_img, cv2.COLOR_BGR2GRAY)
                                
                                # OCR ìˆ˜í–‰ (í´ì§„ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•¨)
                                ocr_texts = self.reader.readtext(warped_gray, detail=0)
                                if len(ocr_texts) > 0:
                                    # ê³µë°± ì œê±° ë° ì¸ì‹ ê²°ê³¼ ì €ì¥
                                    self.detection_result["text"] = "".join(ocr_texts).replace(" ", "")
                                    log_print(f"ì¸ì‹ëœ ë²ˆí˜¸íŒ: {self.detection_result['text']}")
                            except Exception as e:
                                log_print(f"OCR ì›Œí•‘ ì—ëŸ¬: {e}")
                        
                        break 
                    if found: break

                if not found:
                    self.detection_result["detected"] = False
                    self.detection_result["box"] = None
                    self.detection_result["text"] = ""
            
            except Exception as e:
                log_print(f"ğŸ”¥ ê°ì§€ ìŠ¤ë ˆë“œ ì—ëŸ¬: {e}")
                time.sleep(1.0)
                
            time.sleep(0.01)