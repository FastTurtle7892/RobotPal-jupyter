# robot_vision.py
import threading
import time
import cv2
import torch
import torchvision
import torchvision.transforms as transforms
import PIL.Image
import easyocr
import numpy as np
from ultralytics import YOLO
from .robot_config import log_print, REF_DISTANCE_CM, REF_HEIGHT_PX

class VisionSystem:
    def __init__(self):
        self.device = torch.device('cuda')
        
        # --- ResNet (ì¡°í–¥) ëª¨ë¸ ë¡œë“œ ---
        log_print(">>> ì¡°í–¥ ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.steering_model = torchvision.models.resnet18(pretrained=False)
        self.steering_model.fc = torch.nn.Linear(512, 2)
        # ê²½ë¡œê°€ ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
        self.steering_model.load_state_dict(torch.load('best_steering_model_xy_test_12_17.pth', map_location=self.device))
        self.steering_model = self.steering_model.to(self.device).eval().half()
        
        self.mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()
        self.std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()

        # --- YOLO & OCR ëª¨ë¸ ë¡œë“œ ---
        log_print(">>> YOLO ë° OCR ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model_yolo = YOLO("runs/obb/train/weights/best.pt")
        self.reader = easyocr.Reader(['en'], gpu=True) # OCR ë¦¬ë” ë¯¸ë¦¬ ë¡œë“œ ê¶Œì¥
        
        # --- ìŠ¤ë ˆë“œ ê³µìœ  ë³€ìˆ˜ ---
        self.stop_thread = False
        self.detection_thread = None
        self.latest_image_lock = threading.Lock()
        self.shared_latest_image = None
        
        self.detection_result = {
            "box": None,
            "dist_cm": None,
            "detected": False,
            "text": "" 
        }
        log_print(">>> ë¹„ì „ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def preprocess(self, image):
        """ResNetìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        image = PIL.Image.fromarray(image)
        image = transforms.functional.to_tensor(image).to(self.device).half()
        image.sub_(self.mean[:, None, None]).div_(self.std[:, None, None])
        return image[None, ...]

    def update_image(self, image):
        """ë©”ì¸ ë£¨í”„ì—ì„œ ìµœì‹  ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì˜´"""
        with self.latest_image_lock:
            self.shared_latest_image = image

    def start_detection_thread(self):
        """ê°ì§€ ìŠ¤ë ˆë“œ ì‹œì‘"""
        if self.detection_thread is not None:
            self.stop_thread = True
            self.detection_thread.join()
        
        self.stop_thread = False
        self.detection_thread = threading.Thread(target=self._detection_worker)
        self.detection_thread.start()

    def stop_detection_thread(self):
        """ê°ì§€ ìŠ¤ë ˆë“œ ì¤‘ì§€"""
        self.stop_thread = True
        if self.detection_thread:
            self.detection_thread.join()

    def _detection_worker(self):
        log_print(">>> ê°ì§€ ìŠ¤ë ˆë“œ ì‹œì‘ë¨")
        while not self.stop_thread:
            img_input = None
            with self.latest_image_lock:
                if self.shared_latest_image is not None:
                    img_input = self.shared_latest_image.copy()
            
            if img_input is None:
                time.sleep(0.01)
                continue

            try:
                # YOLO ì¶”ë¡ 
                results = self.model_yolo(img_input, verbose=False, conf=0.1) 
                
                found = False
                for result in results:
                    # [ìˆ˜ì • 1] OBB ëª¨ë¸ì€ result.boxes ëŒ€ì‹  result.obbë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
                    # ê°ì§€ëœ ê²ƒì´ ì—†ìœ¼ë©´ result.obbëŠ” Noneì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    if result.obb is None:
                        continue

                    # result.obbë¥¼ ë°˜ë³µí•©ë‹ˆë‹¤.
                    for obb in result.obb:
                        # [ìˆ˜ì • 2] OBB ì¢Œí‘œ ë³€í™˜
                        # OBBëŠ” ê¸°ìš¸ì–´ì§„ ì‚¬ê°í˜•ì´ë¯€ë¡œ 4ê°œì˜ ì (xyxyxyxy)ì„ ì¤ë‹ˆë‹¤.
                        # ê¸°ì¡´ ë¡œì§(ê±°ë¦¬ ê³„ì‚°, OCR crop)ì„ ìœ„í•´ ì´ë¥¼ í¬í•¨í•˜ëŠ” ì •ë°©í˜• ë°•ìŠ¤(x1,y1,x2,y2)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
                        corners = obb.xyxyxyxy.cpu().numpy()[0] # shape: (4, 2)
                        
                        x_coords = corners[:, 0]
                        y_coords = corners[:, 1]
                        
                        x1 = int(np.min(x_coords))
                        y1 = int(np.min(y_coords))
                        x2 = int(np.max(x_coords))
                        y2 = int(np.max(y_coords))
                        
                        h_pixel = y2 - y1
                        dist = (REF_DISTANCE_CM * REF_HEIGHT_PX) / h_pixel if h_pixel > 0 else 0

                        self.detection_result["box"] = (x1, y1, x2, y2)
                        self.detection_result["dist_cm"] = dist
                        self.detection_result["detected"] = True
                        found = True
                        
                        # 120cm ì´ë‚´ OCR ìˆ˜í–‰
                        if dist < 120.0:
                            try:
                                h, w, _ = img_input.shape
                                x1 = max(0, x1); y1 = max(0, y1)
                                x2 = min(w, x2); y2 = min(h, y2)
                                crop_img = img_input[y1:y2, x1:x2]
                                
                                if crop_img.shape[0] > 0 and crop_img.shape[1] > 0:
                                    ocr_texts = self.reader.readtext(crop_img, detail=0)
                                    if len(ocr_texts) > 0:
                                        self.detection_result["text"] = " ".join(ocr_texts)
                            except: pass
                        
                        # ê°€ì¥ ê°€ê¹Œìš´(ë˜ëŠ” ì‹ ë¢°ë„ ë†’ì€) í•˜ë‚˜ë§Œ ì²˜ë¦¬í•˜ê³  break
                        break 
                    if found: break

                if not found:
                    self.detection_result["detected"] = False
                    self.detection_result["box"] = None
            
            except Exception as e:
                # ì—ëŸ¬ ë¡œê·¸ê°€ ë„ˆë¬´ ë§ì´ ëœ¨ì§€ ì•Šê²Œ 1ì´ˆ ëŒ€ê¸°
                log_print(f"ğŸ”¥ ê°ì§€ ìŠ¤ë ˆë“œ ì—ëŸ¬: {e}")
                time.sleep(1.0)
                
            time.sleep(0.01)