{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RobotPal] ì„œë²„ ì‹œì‘ë¨ | WebSocket: 9999, TCP: 9998\n",
      "[RobotPal] í†µì‹  ëŒ€ê¸° ì¤‘... (WS: 9999, TCP: 9998)\n",
      "[System] WebSocket í”„ë¡œì„¸ì„œ ì‹œì‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs\\\\detect\\\\train\\\\weights\\\\best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m     image.sub_(mean[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]).div_(std[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m image[\u001b[38;5;28;01mNone\u001b[39;00m, ...]\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m model_yolo = \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mruns/detect/train/weights/best.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ultralytics\\models\\yolo\\model.py:76\u001b[39m, in \u001b[36mYOLO.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = new_instance.\u001b[34m__dict__\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     75\u001b[39m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mRTDETR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.model[-\u001b[32m1\u001b[39m]._get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ultralytics\\engine\\model.py:144\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28mself\u001b[39m._new(model, task=task, verbose=verbose)\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ultralytics\\engine\\model.py:283\u001b[39m, in \u001b[36mModel._load\u001b[39m\u001b[34m(self, weights, task)\u001b[39m\n\u001b[32m    280\u001b[39m weights = checks.check_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights).rpartition(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.ckpt = \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m     \u001b[38;5;28mself\u001b[39m.task = \u001b[38;5;28mself\u001b[39m.model.task\n\u001b[32m    285\u001b[39m     \u001b[38;5;28mself\u001b[39m.overrides = \u001b[38;5;28mself\u001b[39m.model.args = \u001b[38;5;28mself\u001b[39m._reset_ckpt_args(\u001b[38;5;28mself\u001b[39m.model.args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ultralytics\\nn\\tasks.py:1461\u001b[39m, in \u001b[36mload_checkpoint\u001b[39m\u001b[34m(weight, device, inplace, fuse)\u001b[39m\n\u001b[32m   1448\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_checkpoint\u001b[39m(weight, device=\u001b[38;5;28;01mNone\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m, fuse=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1449\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a single model weights.\u001b[39;00m\n\u001b[32m   1450\u001b[39m \n\u001b[32m   1451\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1459\u001b[39m \u001b[33;03m        ckpt (dict): Model checkpoint dictionary.\u001b[39;00m\n\u001b[32m   1460\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1461\u001b[39m     ckpt, weight = \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[32m   1462\u001b[39m     args = {**DEFAULT_CFG_DICT, **(ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mtrain_args\u001b[39m\u001b[33m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[32m   1463\u001b[39m     model = (ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mema\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]).float()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ultralytics\\nn\\tasks.py:1409\u001b[39m, in \u001b[36mtorch_safe_load\u001b[39m\u001b[34m(weight, safe_only)\u001b[39m\n\u001b[32m   1407\u001b[39m                 ckpt = torch_load(f, pickle_module=safe_pickle)\n\u001b[32m   1408\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1409\u001b[39m             ckpt = \u001b[43mtorch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[32m   1412\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.name == \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ultralytics\\utils\\patches.py:116\u001b[39m, in \u001b[36mtorch_load\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    114\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\serialization.py:1484\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1482\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1486\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1487\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1488\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1489\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'runs\\\\detect\\\\train\\\\weights\\\\best.pt'"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import PIL.Image\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "from ultralytics import YOLO  # YOLO ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€\n",
    "from robotpal import Robot, Camera, bgr8_to_jpeg\n",
    "from robotpal.SCSCtrl import TTLServo\n",
    "import os\n",
    "from datetime import datetime\n",
    "import ipywidgets.widgets as widgets\n",
    "import easyocr\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model.load_state_dict(torch.load('best_steering_model_xy_test_12_17.pth', map_location=torch.device('cuda')))\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model = model.eval().half()\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "model_yolo = YOLO(\"runs/detect/train/weights/best.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Send Servo] ID: 5, Angle: 24.988235294117647, Speed: 20.0\n",
      "[Send Servo] ID: 1, Angle: 0.0, Speed: 20.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b47dc0e08342fcb52106207dab788c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='500', width='500')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0823f5aeae435aab51795ef7ef51bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='[00:13:54] >>> OCR ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\\n[00:13:51] >>> OCR ëª¨ë¸ ë¡œë”© ì¤‘...\\n[00:13:51] >>> ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...\\n[00â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b26f5780464d88b1b0d62a88df2347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.0, description='y', max=1.0, orientation='vertical'), FloatSlider(value=0.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2584978cd74877879e59780a5938e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='x', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0faacaf13546929a2bcf4a5386a0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "opening handshake failed\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\websockets\\asyncio\\server.py\", line 356, in conn_handler\n",
      "    await connection.handshake(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\websockets\\asyncio\\server.py\", line 207, in handshake\n",
      "    raise self.protocol.handshake_exc\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\websockets\\server.py\", line 138, in accept\n",
      "    ) = self.process_request(request)\n",
      "        ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\websockets\\server.py\", line 233, in process_request\n",
      "    raise InvalidUpgrade(\n",
      "        \"Connection\", \", \".join(connection) if connection else None\n",
      "    )\n",
      "websockets.exceptions.InvalidUpgrade: missing Connection header\n",
      "Unhandled exception in client_connected_cb\n",
      "transport: <_SelectorSocketTransport closed fd=2284>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\jupyter ex\\robotpal\\_core\\server.py\", line 180, in _handle_tcp\n",
      "    await writer.wait_closed()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\streams.py\", line 358, in wait_closed\n",
      "    await self._protocol._get_close_waiter(self)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\selector_events.py\", line 1005, in _read_ready__data_received\n",
      "    data = self._sock.recv(self.max_size)\n",
      "ConnectionResetError: [WinError 10054] í˜„ì¬ ì—°ê²°ì€ ì›ê²© í˜¸ìŠ¤íŠ¸ì— ì˜í•´ ê°•ì œë¡œ ëŠê²¼ìŠµë‹ˆë‹¤\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TCP] ì˜ˆì™¸ ë°œìƒ: [WinError 10054] í˜„ì¬ ì—°ê²°ì€ ì›ê²© í˜¸ìŠ¤íŠ¸ì— ì˜í•´ ê°•ì œë¡œ ëŠê²¼ìŠµë‹ˆë‹¤\n",
      "[TCP] ì—°ê²° ì¢…ë£Œ (('127.0.0.1', 49235))\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. ì´ˆê¸° ì„¤ì • ë° ë¡œê·¸ ì°½(Textarea) ìƒì„±\n",
    "# ==========================================\n",
    "CAM_WIDTH = 816\n",
    "CAM_HEIGHT = 616\n",
    "\n",
    "# [ìˆ˜ì •ë¨] Output ìœ„ì ¯ ëŒ€ì‹  Textarea ì‚¬ìš© (í™•ì‹¤í•œ ë¡œê·¸ ì¶œë ¥ìš©)\n",
    "log_widget = ipywidgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder=\"ë¡œê·¸ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤...\",\n",
    "    description=\"ğŸ“ LOG:\",\n",
    "    disabled=True, # ìˆ˜ì • ë¶ˆê°€ëŠ¥í•˜ê²Œ ì„¤ì •\n",
    "    layout=ipywidgets.Layout(width='600px', height='200px')\n",
    ")\n",
    "\n",
    "def log_print(msg):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ìƒìì— ë©”ì‹œì§€ë¥¼ ì§ì ‘ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "    new_line = f\"[{timestamp}] {msg}\\n\"\n",
    "    # ìƒˆë¡œìš´ ë¡œê·¸ë¥¼ ë§¨ ìœ„ì— ì¶”ê°€ (ìµœì‹ ìˆœ)\n",
    "    log_widget.value = new_line + log_widget.value \n",
    "\n",
    "\n",
    "robot = Robot()\n",
    "camera = Camera.instance(width=CAM_WIDTH, height=CAM_HEIGHT)\n",
    "TTLServo.servoAngleCtrl(5, -25, 1, 100)\n",
    "TTLServo.servoAngleCtrl(1, 0, 1, 100)\n",
    "\n",
    "# ==========================================\n",
    "# 2. ìœ„ì ¯ ìƒì„± ë° ë°°ì¹˜\n",
    "# ==========================================\n",
    "image_widget = ipywidgets.Image(format='jpeg', width=500, height=500)\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "display(image_widget)\n",
    "display(log_widget) # <--- [ìˆ˜ì •ë¨] í…ìŠ¤íŠ¸ ìƒì í‘œì‹œ\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. ê°ì§€ ìŠ¤ë ˆë“œ\n",
    "# ==========================================\n",
    "stop_thread = False\n",
    "detection_thread = None\n",
    "latest_image_lock = threading.Lock()\n",
    "shared_latest_image = None\n",
    "\n",
    "detection_result = {\n",
    "    \"box\": None,\n",
    "    \"dist_cm\": None,\n",
    "    \"detected\": False,\n",
    "    \"text\": \"\" \n",
    "}\n",
    "\n",
    "REF_DISTANCE_CM = 60.0\n",
    "REF_HEIGHT_PX = 110.0\n",
    "\n",
    "def detection_worker():\n",
    "    global shared_latest_image, stop_thread, detection_result\n",
    "\n",
    "    log_print(\">>> ê°ì§€ ìŠ¤ë ˆë“œ ì‹œì‘ë¨\")\n",
    "\n",
    "    while not stop_thread:\n",
    "        img_input = None\n",
    "        with latest_image_lock:\n",
    "            if shared_latest_image is not None:\n",
    "                img_input = shared_latest_image.copy()\n",
    "        \n",
    "        if img_input is None:\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # YOLO ì¶”ë¡ \n",
    "            results = model_yolo(img_input, verbose=False, conf=0.1) \n",
    "            \n",
    "            found = False\n",
    "            for result in results:\n",
    "                for box in result.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "                    \n",
    "                    h_pixel = y2 - y1\n",
    "                    dist = (REF_DISTANCE_CM * REF_HEIGHT_PX) / h_pixel if h_pixel > 0 else 0\n",
    "\n",
    "                    detection_result[\"box\"] = (x1, y1, x2, y2)\n",
    "                    detection_result[\"dist_cm\"] = dist\n",
    "                    detection_result[\"detected\"] = True\n",
    "                    found = True\n",
    "                    \n",
    "                    # 120cm ì´ë‚´ OCR ìˆ˜í–‰\n",
    "                    if dist < 120.0:\n",
    "                        try:\n",
    "                            h, w, _ = img_input.shape\n",
    "                            x1 = max(0, x1); y1 = max(0, y1)\n",
    "                            x2 = min(w, x2); y2 = min(h, y2)\n",
    "                            \n",
    "                            crop_img = img_input[y1:y2, x1:x2]\n",
    "                            \n",
    "                            if crop_img.shape[0] > 0 and crop_img.shape[1] > 0:\n",
    "                                ocr_texts = reader.readtext(crop_img, detail=0)\n",
    "                                if len(ocr_texts) > 0:\n",
    "                                    detection_result[\"text\"] = \" \".join(ocr_texts)\n",
    "                        except: pass\n",
    "                    break \n",
    "                if found: break\n",
    "\n",
    "            if not found:\n",
    "                detection_result[\"detected\"] = False\n",
    "                detection_result[\"box\"] = None\n",
    "        \n",
    "        except Exception as e:\n",
    "            log_print(f\"ğŸ”¥ ê°ì§€ ìŠ¤ë ˆë“œ ì—ëŸ¬: {e}\")\n",
    "            time.sleep(1.0)\n",
    "            \n",
    "        time.sleep(0.01)\n",
    "\n",
    "# ìŠ¤ë ˆë“œ ì¬ì‹œì‘\n",
    "stop_thread = True\n",
    "if detection_thread is not None:\n",
    "    detection_thread.join(timeout=1.0)\n",
    "\n",
    "stop_thread = False\n",
    "shared_latest_image = None\n",
    "detection_result = {\"box\": None, \"dist_cm\": None, \"detected\": False, \"text\": \"\"}\n",
    "\n",
    "detection_thread = threading.Thread(target=detection_worker)\n",
    "detection_thread.start()\n",
    "\n",
    "# ==========================================\n",
    "# 4. ë©”ì¸ ì‹¤í–‰ ë£¨í”„\n",
    "# ==========================================\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "stop_end_time = 0.0\n",
    "is_stopped = False\n",
    "frame_count = 0\n",
    "ignore_detection_until = 0.0 \n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last, is_stopped, stop_end_time, frame_count\n",
    "    global shared_latest_image, ignore_detection_until\n",
    "\n",
    "    try:\n",
    "        image = change['new']\n",
    "        current_time = time.time()\n",
    "        frame_count += 1\n",
    "\n",
    "        with latest_image_lock:\n",
    "            shared_latest_image = image\n",
    "\n",
    "        vis_image = image.copy()\n",
    "        \n",
    "        cur_box = detection_result[\"box\"]\n",
    "        cur_dist = detection_result[\"dist_cm\"]\n",
    "        is_detected = detection_result[\"detected\"]\n",
    "        cur_text = detection_result[\"text\"]\n",
    "\n",
    "        # --- [ìƒíƒœ 1] ì •ì§€ ëª¨ë“œ ---\n",
    "        if is_stopped:\n",
    "            if current_time < stop_end_time:\n",
    "                cv2.putText(vis_image, \"STOP MODE\", (10, 40), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)\n",
    "\n",
    "                remain_time = stop_end_time - current_time\n",
    "                cv2.putText(vis_image, f\"{remain_time:.1f}s\", (10, 80), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)\n",
    "                \n",
    "                if cur_box is not None:\n",
    "                    x1, y1, x2, y2 = cur_box\n",
    "                    cv2.rectangle(vis_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 3)\n",
    "                \n",
    "                robot.left_motor.value = 0.0\n",
    "                robot.right_motor.value = 0.0\n",
    "                image_widget.value = bgr8_to_jpeg(vis_image)\n",
    "                return\n",
    "            else:\n",
    "                is_stopped = False\n",
    "                ignore_detection_until = current_time + 3.0 \n",
    "                log_print(\">>> ì£¼í–‰ ì¬ê°œ (1.5ì´ˆê°„ ì¿¨ë‹¤ìš´)\")\n",
    "\n",
    "        # --- [ìƒíƒœ 2] ì£¼í–‰ ì¤‘ ê°ì§€ ---\n",
    "        if is_detected and cur_dist is not None:\n",
    "            x1, y1, x2, y2 = cur_box\n",
    "            color = (0, 255, 255) if current_time < ignore_detection_until else (0, 255, 0)\n",
    "            \n",
    "            cv2.rectangle(vis_image, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "\n",
    "            # ì •ì§€ ì¡°ê±´ (200cm ë¯¸ë§Œ)\n",
    "            if cur_dist < 150.0 and current_time > ignore_detection_until:\n",
    "                is_stopped = True\n",
    "                stop_end_time = current_time + 1.5\n",
    "                \n",
    "                # ì •ì§€í•  ë•Œ ë¡œê·¸ ì¶œë ¥\n",
    "                log_print(f\"ğŸ›‘ ì •ì§€! (ê±°ë¦¬: {cur_dist:.1f}cm) / ë²ˆí˜¸íŒ: [{cur_text}]\")\n",
    "                    \n",
    "                robot.left_motor.value = 0.0\n",
    "                robot.right_motor.value = 0.0\n",
    "                image_widget.value = bgr8_to_jpeg(vis_image)\n",
    "                return\n",
    "\n",
    "        image_widget.value = bgr8_to_jpeg(vis_image)\n",
    "\n",
    "        # --- [ìƒíƒœ 3] ììœ¨ ì£¼í–‰ ---\n",
    "        # ë¦¬ì‚¬ì´ì¦ˆ ì—†ì´ ì‹¤í–‰ (ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ ì¶œë ¥)\n",
    "        xy = model(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "        \n",
    "        x = xy[0]\n",
    "        y = (0.5 - xy[1]) / 2.0\n",
    "        \n",
    "        speed_slider.value = 0.32\n",
    "        \n",
    "        angle = np.arctan2(x, y)\n",
    "        pid = angle * 0.2 + (angle - angle_last) * 0.5\n",
    "        angle_last = angle\n",
    "        \n",
    "        steering_slider.value = pid + 0\n",
    "        left_val = max(min(speed_slider.value + steering_slider.value, 1.0), -0.9)\n",
    "        right_val = max(min(speed_slider.value - steering_slider.value, 1.0), -0.9)\n",
    "        \n",
    "        robot.left_motor.value = float(left_val)\n",
    "        robot.right_motor.value = float(right_val)\n",
    "        \n",
    "    except Exception as e:\n",
    "        robot.left_motor.value = 0.0\n",
    "        robot.right_motor.value = 0.0\n",
    "        log_print(f\"ğŸš¨ ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "        time.sleep(1.0)\n",
    "\n",
    "# ì‹¤í–‰ ì‹œì‘\n",
    "try: camera.unobserve_all()\n",
    "except: pass\n",
    "execute({'new': camera.value})\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í”„ë¡œì íŠ¸ ì¢…ë£Œí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "camera.unobserve(execute, names='value')\n",
    "time.sleep(0.1) \n",
    "robot.stop()\n",
    "camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
